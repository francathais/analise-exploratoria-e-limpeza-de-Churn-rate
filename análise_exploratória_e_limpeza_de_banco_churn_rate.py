# -*- coding: utf-8 -*-
"""Análise exploratória e limpeza de banco Churn rate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WOHEhwNNBMrrUGcrYmhKRTzYTK2L0NzU

# Apresentação do banco: Dados de instuição financeira, com objetivo de analise Churn (prevenção de saída de cliente)
#Proposta: Análise exploratória, Limpeza de dados
"""

import statistics as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as srs
import io

import seaborn as sns
 sns.__version__

pip install statistics

from google.colab import files
uploaded = files.upload()

dataset = pd.read_csv("Churn.csv", sep=";") #Chamando pelo nome o arquivo: dataset
dataset.head() #ler

dataset.shape #tamanho

dataset.columns = ["Id", "Score", "Estado", "Genero", "Idade", "Patrimonio", "Saldo", "Produtos", "TemCardCredito", "Ativo", "Salario", "Saiu"]
#dar nomes às colunas

dataset.head() #ler

"""#Análise exploratória """

#Estado
agrupando = dataset.groupby(['Estado']).size()

agrupando

agrupando.plot.bar(color="pink")

"""Necessário tratar dados errados"""

#Gênero
agrupando = dataset.groupby(['Genero']).size()

agrupando

agrupando.plot.bar(color="pink")

"""Necessário unificar nome das variaveis"""

#colunas numericas
#variavel Score
dataset["Score"].describe()

"""Média e mediana prox, distribuição parecida, sem muitos outliers """

#boxplot
srn.boxplot(dataset["Score"]).set_title('Score')

#histograma
srn.distplot(dataset["Score"]).set_title('Score')

#Idade
dataset['Idade'].describe()

srn.boxplot(dataset["Idade"]).set_title('Idade')

srn.distplot(dataset["Idade"]).set_title('Idade')

"""resolver o -20 e 140"""

#Saldo
dataset['Saldo'].describe()

srn.boxplot(dataset["Saldo"]).set_title('Saldo')

srn.distplot(dataset["Saldo"]).set_title('Saldo')

dataset["Salario"].describe()

srn.boxplot(dataset["Salario"]).set_title('Salario')

srn.distplot(dataset["Salario"]).set_title('Salario')

"""Corrigir distorção"""

# contando em SALARIOS valores NA (sm respostas)
dataset.isnull().sum()

"""#Correções

Gênero
"""

#Genero: preencher NA e padronizar titulo das variaveis
agrupando = dataset.groupby(['Genero']).size()
agrupando

dataset['Genero'].isnull().sum()

"""Preencher os NA com masculino, porque sao os que mais ocorrem na Moda calculada pelo agrupamento. No caso de masculino poe o ""
inplace troca
"""

#SUBSTITUIÇÃO fillna substitui os valores vazios (aqui, pelo Masculino)
dataset['Genero'].fillna('Masculino', inplace=True)

dataset['Genero'].isnull().sum()

dataset.loc[dataset['Genero']=='M','Genero']= "Masculino"
dataset.loc[dataset['Genero'].isin(['fe', 'F', "Fem"]), 'Genero']= 'Feminino'
#visualizar
agrupado = dataset.groupby(['Genero']).size()
agrupado

"""Idade"""

dataset['Idade'].describe()

#visualizar
dataset.loc[(dataset['Idade'] < 0 ) |(dataset['Idade']>120)] #REVER ESSE CÓDIGO

"""Calcular a mediana para estabelecer critério. A mediana é menos sujeita a outlier"""

mediana=sts.median(dataset["Idade"]) #calcula a mediana
mediana

dataset.loc[(dataset['Idade'] <0) | (dataset["Idade"]>120),"Idade"]=mediana #substitui #REVER ESSE CÓDIGO

#visualizar novamente
dataset.loc[(dataset['Idade'] < 0 ) |(dataset['Idade']>120)] #REVER ESSE CÓDIGO

"""Salário"""

#Salario
dataset["Salario"].describe()

mediana=sts.median(dataset["Salario"])

mediana

#SUBSTITUIÇÃO fillna substitui os valores vazios (aqui, pela mediana)
dataset['Salario'].fillna(mediana, inplace=True)

#CONTANDO OS NA
dataset['Salario'].isnull().sum()

"""Agora é 0, antes era 7

Limpando id de repetição
"""

#Limpando Id repetido
dataset[dataset.duplicated(["Id"],keep=False)]

dataset.drop_duplicates(subset="Id", keep="first", inplace=True) #busca os duplicados em id> keep mantem o primeiro e tira o segundo>inplace substitui no proprio banco de dados
dataset[dataset.duplicated(["Id"], keep=False)]

#ver estados fora do dominio
agrupado=dataset.groupby(['Estado']).size()
agrupado

dataset.loc[dataset['Estado'].isin(['RP','SP','TD']), 'Estado']='RS' substitui pela moda, como no Feminino
agrupado=dataset.groupby(['Estado']).size()

agrupado
